{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for SGDClassifier: {'max_iter': 3000, 'alpha': 0.001}\n",
      "Best hyperparameters for MLP: {'hidden_layer_sizes': (50,), 'alpha': 0.01}\n",
      "SGDClassifier Metrics:\n",
      "Accuracy: 0.6505\n",
      "Precision: 0.6505\n",
      "Recall: 1.0\n",
      "F1 Score: 0.7882459860648288\n",
      "\n",
      "MLP Metrics:\n",
      "Accuracy: 0.6505\n",
      "Precision: 0.6505\n",
      "Recall: 1.0\n",
      "F1 Score: 0.7882459860648288\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier  # Changed\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the project dataset\n",
    "data = pd.read_csv(\"D:\\\\WORK\\\\machine learning\\\\customer_churn.csv\")\n",
    "data.describe()\n",
    "data.shape\n",
    "data.isnull().sum()\n",
    "data=data.dropna()\n",
    "data.isnull().sum()\n",
    "\n",
    "# Encode target variable based on price movement\n",
    "data['Target'] = np.where(data['Balance'] > data['CreditScore'], 1, 0)\n",
    "\n",
    "# Define features and target variable for the project dataset\n",
    "X_project = data[['CreditScore']]\n",
    "y_project = data['Target']\n",
    "\n",
    "# Split the project dataset into training and testing sets\n",
    "X_train_project, X_test_project, y_train_project, y_test_project = train_test_split(X_project, y_project, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SGDClassifier and MLP classifiers\n",
    "sgd_classifier = SGDClassifier()  # Changed\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Define parameter grids for hyperparameter tuning\n",
    "param_grid_sgd = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0], 'max_iter': [1000, 2000, 3000]}  # Changed\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "# Perform hyperparameter tuning for SGDClassifier using RandomizedSearchCV\n",
    "random_search_sgd = RandomizedSearchCV(sgd_classifier, param_distributions=param_grid_sgd, n_iter=5, cv=5, random_state=42)\n",
    "random_search_sgd.fit(X_train_project, y_train_project)\n",
    "best_params_sgd = random_search_sgd.best_params_\n",
    "\n",
    "# Perform hyperparameter tuning for MLP using RandomizedSearchCV\n",
    "random_search_mlp = RandomizedSearchCV(mlp, param_distributions=param_grid_mlp, n_iter=5, cv=5, random_state=42)\n",
    "random_search_mlp.fit(X_train_project, y_train_project)\n",
    "best_params_mlp = random_search_mlp.best_params_\n",
    "\n",
    "# Train and evaluate SGDClassifier and MLP models with best hyperparameters\n",
    "sgd_classifier.set_params(**best_params_sgd)\n",
    "mlp.set_params(**best_params_mlp)\n",
    "\n",
    "sgd_classifier.fit(X_train_project, y_train_project)\n",
    "mlp.fit(X_train_project, y_train_project)\n",
    "\n",
    "y_pred_sgd = sgd_classifier.predict(X_test_project)\n",
    "y_pred_mlp = mlp.predict(X_test_project)\n",
    "\n",
    "accuracy_sgd = accuracy_score(y_test_project, y_pred_sgd)\n",
    "precision_sgd = precision_score(y_test_project, y_pred_sgd)\n",
    "recall_sgd = recall_score(y_test_project, y_pred_sgd)\n",
    "f1_sgd = f1_score(y_test_project, y_pred_sgd)\n",
    "\n",
    "accuracy_mlp = accuracy_score(y_test_project, y_pred_mlp)\n",
    "precision_mlp = precision_score(y_test_project, y_pred_mlp)\n",
    "recall_mlp = recall_score(y_test_project, y_pred_mlp)\n",
    "f1_mlp = f1_score(y_test_project, y_pred_mlp)\n",
    "\n",
    "# Print the best hyperparameters for SGDClassifier and MLP\n",
    "print(\"Best hyperparameters for SGDClassifier:\", best_params_sgd)\n",
    "print(\"Best hyperparameters for MLP:\", best_params_mlp)\n",
    "\n",
    "# Print the evaluation metrics for SGDClassifier\n",
    "print(\"SGDClassifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_sgd)\n",
    "print(\"Precision:\", precision_sgd)\n",
    "print(\"Recall:\", recall_sgd)\n",
    "print(\"F1 Score:\", f1_sgd)\n",
    "\n",
    "# Print the evaluation metrics for MLP\n",
    "print(\"\\nMLP Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_mlp)\n",
    "print(\"Precision:\", precision_mlp)\n",
    "print(\"Recall:\", recall_mlp)\n",
    "print(\"F1 Score:\", f1_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.650500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.650821</td>\n",
       "      <td>0.883935</td>\n",
       "      <td>0.749674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.650475</td>\n",
       "      <td>0.895465</td>\n",
       "      <td>0.753558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.651104</td>\n",
       "      <td>0.996925</td>\n",
       "      <td>0.787732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.650500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classifier  Accuracy  Precision    Recall  F1 Score\n",
       "0            SVM    0.6505   0.650500  1.000000  0.788246\n",
       "1  Decision Tree    0.6160   0.650821  0.883935  0.749674\n",
       "2  Random Forest    0.6190   0.650475  0.895465  0.753558\n",
       "3       AdaBoost    0.6505   0.651104  0.996925  0.787732\n",
       "4    Naive Bayes    0.6505   0.650500  1.000000  0.788246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier  # Changed\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC  # Changed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the project dataset\n",
    "data = pd.read_csv(\"D:\\\\WORK\\\\machine learning\\\\customer_churn.csv\")\n",
    "data.describe()\n",
    "data.shape\n",
    "data.isnull().sum()\n",
    "data = data.dropna()\n",
    "data.isnull().sum()\n",
    "\n",
    "# Encode target variable based on price movement\n",
    "data['Target'] = np.where(data['Balance'] > data['CreditScore'], 1, 0)\n",
    "\n",
    "# Define features and target variable for the project dataset\n",
    "X_project = data[['CreditScore']]\n",
    "y_project = data['Target']\n",
    "\n",
    "# Split the project dataset into training and testing sets\n",
    "X_train_project, X_test_project, y_train_project, y_test_project = train_test_split(X_project, y_project, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the perceptron and MLP classifiers\n",
    "perceptron = SGDClassifier(loss='perceptron')  # Changed\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Define parameter grids for hyperparameter tuning\n",
    "param_grid_perceptron = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0], 'max_iter': [1000, 2000, 3000]}\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "# Tune hyperparameters for perceptron and MLP using RandomizedSearchCV\n",
    "random_search_perceptron = RandomizedSearchCV(perceptron, param_distributions=param_grid_perceptron, n_iter=5, cv=5, random_state=42)\n",
    "random_search_perceptron.fit(X_train_project, y_train_project)\n",
    "best_params_perceptron = random_search_perceptron.best_params_\n",
    "\n",
    "random_search_mlp = RandomizedSearchCV(mlp, param_distributions=param_grid_mlp, n_iter=5, cv=5, random_state=42)\n",
    "random_search_mlp.fit(X_train_project, y_train_project)\n",
    "best_params_mlp = random_search_mlp.best_params_\n",
    "\n",
    "# Train and evaluate perceptron and MLP models\n",
    "perceptron.set_params(**best_params_perceptron)\n",
    "mlp.set_params(**best_params_mlp)\n",
    "\n",
    "perceptron.fit(X_train_project, y_train_project)\n",
    "mlp.fit(X_train_project, y_train_project)\n",
    "\n",
    "y_pred_perceptron = perceptron.predict(X_test_project)\n",
    "y_pred_mlp = mlp.predict(X_test_project)\n",
    "\n",
    "accuracy_perceptron = accuracy_score(y_test_project, y_pred_perceptron)\n",
    "precision_perceptron = precision_score(y_test_project, y_pred_perceptron)\n",
    "recall_perceptron = recall_score(y_test_project, y_pred_perceptron)\n",
    "f1_perceptron = f1_score(y_test_project, y_pred_perceptron)\n",
    "\n",
    "accuracy_mlp = accuracy_score(y_test_project, y_pred_mlp)\n",
    "precision_mlp = precision_score(y_test_project, y_pred_mlp)\n",
    "recall_mlp = recall_score(y_test_project, y_pred_mlp)\n",
    "f1_mlp = f1_score(y_test_project, y_pred_mlp)\n",
    "\n",
    "# Initialize other classifiers\n",
    "svm = LinearSVC()  # Changed\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Train and evaluate other classifiers\n",
    "classifiers = {\n",
    "    'SVM': svm,\n",
    "    'Decision Tree': decision_tree,\n",
    "    'Random Forest': random_forest,\n",
    "    'AdaBoost': adaboost,\n",
    "    'Naive Bayes': naive_bayes\n",
    "}\n",
    "\n",
    "results = {'Classifier': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1 Score': []}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_project, y_train_project)\n",
    "    y_pred = clf.predict(X_test_project)\n",
    "    accuracy = accuracy_score(y_test_project, y_pred)\n",
    "    precision = precision_score(y_test_project, y_pred)\n",
    "    recall = recall_score(y_test_project, y_pred)\n",
    "    f1 = f1_score(y_test_project, y_pred)\n",
    "    \n",
    "    results['Classifier'].append(name)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Precision'].append(precision)\n",
    "    results['Recall'].append(recall)\n",
    "    results['F1 Score'].append(f1)\n",
    "\n",
    "# Create a DataFrame to tabulate the results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
